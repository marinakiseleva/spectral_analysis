{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory structure check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make all necesssary directories if they don't already exist. However, these directories would all be empty. The proper files must be placed in each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils.constants import *\n",
    "if not os.path.isdir(DATA_DIR):\n",
    "    print(\"Missing data directory. Creating here: \" + ROOT_DIR)\n",
    "    os.mkdir(DATA_DIR)\n",
    "\n",
    "if not os.path.isdir(DATA_DIR + \"lab_spectra\"): \n",
    "    print(\"Missing lab spectra directory. Creating here: \" + DATA_DIR)\n",
    "    os.mkdir(DATA_DIR + \"lab_spectra\")\n",
    "    \n",
    "if not os.path.isdir(USGS_DATA): \n",
    "    print(\"Missing USGS lab data directory. Creating here: \" + USGS_DATA)\n",
    "    os.mkdir(USGS_DATA)\n",
    "\n",
    "if not os.path.isdir(PREPROCESSED_DATA): \n",
    "    print(\"Missing PREPROCESSED_DATA directory. Creating here: \" + PREPROCESSED_DATA)\n",
    "    os.mkdir(PREPROCESSED_DATA)\n",
    "    \n",
    "if not os.path.isdir(R_DIR): \n",
    "    print(\"Missing reflectance directory. Creating here: \" + R_DIR)\n",
    "    os.mkdir(R_DIR)\n",
    "    \n",
    "    \n",
    "if not os.path.isdir(K_DIR): \n",
    "    print(\"Missing directory for optical constants K. Creating here: \" + K_DIR)\n",
    "    os.mkdir(K_DIR)\n",
    "    \n",
    "if not os.path.exists(MODULE_DIR + '/output/'):\n",
    "    print(\"Missing directory for experimental output. Creating here:\" + MODULE_DIR + '/output/')\n",
    "    os.makedirs(MODULE_DIR + '/output/')\n",
    "\n",
    "print(\"If any of the following direcotires do not contain all necessary files, the model will not work. \\n\"\n",
    "      + R_DIR  + \" \\n OR \\n\" + K_DIR + \"\\n OR\\n\" + PREPROCESSED_DATA )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Image Generation\n",
    "Create synthetic image resembling some realistic geology to have single, useful test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from model.inference import *\n",
    "from model.hapke_model import get_USGS_r_mixed_hapke_estimate\n",
    "from preprocessing.generate_USGS_data import generate_image\n",
    "from utils.plotting import *\n",
    "from utils.access_data import *\n",
    "from utils.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 2D Numpy Matrix based on circles\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib\n",
    "def points_in_circle_np(radius, x0=0, y0=0):\n",
    "    \"\"\"\n",
    "    Get X, Y coords for given circle\n",
    "    \"\"\"\n",
    "    x_ = np.arange(x0 - radius - 1, x0 + radius + 1, dtype=int)\n",
    "    y_ = np.arange(y0 - radius - 1, y0 + radius + 1, dtype=int)\n",
    "    x, y = np.where((x_[:,np.newaxis] - x0)**2 + (y_ - y0)**2 <= radius**2)\n",
    "    # x, y = np.where((np.hypot((x_-x0)[:,np.newaxis], y_-y0)<= radius)) # alternative implementation\n",
    "    for x, y in zip(x_[x], y_[y]):\n",
    "        yield x, y\n",
    "\n",
    "        \n",
    "\n",
    "img_width = 24\n",
    "img_height = 24\n",
    "color_img = np.zeros((img_width,img_height,3))\n",
    "test_img = np.zeros((img_width,img_height,1))\n",
    "\n",
    "center_X = int(img_height/2)\n",
    "center_Y = int(img_width/2)\n",
    "outer_circle = points_in_circle_np(9, x0=center_X, y0=center_Y)\n",
    "medium_circle =  points_in_circle_np(6, x0=center_X, y0=center_Y)\n",
    "inner_circle =  points_in_circle_np(3, x0=center_X+1, y0=center_Y+1)\n",
    "lower_ring = points_in_circle_np(11, x0=center_X, y0=center_Y-1)\n",
    "\n",
    "circles = [lower_ring, \n",
    "           outer_circle, \n",
    "           medium_circle,\n",
    "           inner_circle]\n",
    "LR_C = [255, 102, 255]\n",
    "O_C = [102, 255, 204]\n",
    "M_C = [51, 51, 255]\n",
    "I_C = [51, 102, 255]\n",
    "\n",
    "RGB_MAP = {0: LR_C,\n",
    "          1: O_C,\n",
    "          2: M_C,\n",
    "          3: I_C}\n",
    "DEFAULT_COLOR =  [153, 51, 51]\n",
    "\n",
    "for row_index, row in enumerate(color_img):\n",
    "    for col_index, col in enumerate(row):\n",
    "        color_img[row_index,col_index] = DEFAULT_COLOR\n",
    "        test_img[row_index,col_index] = 0\n",
    "            \n",
    "for i, circle in enumerate(circles):\n",
    "    for point in circle:\n",
    "        x=point[0]\n",
    "        y=point[1] \n",
    "        if i != 0:\n",
    "            color_img[x,y] = RGB_MAP[i]\n",
    "            test_img[x,y] = i + 1\n",
    "        else:\n",
    "            # only do lower, ring so threshold x \n",
    "            if x >= int(img_height*0.6):\n",
    "                color_img[x,y] = RGB_MAP[i]\n",
    "                test_img[x,y] = i + 1\n",
    "# Plot image\n",
    "figure, ax = plt.subplots(1)\n",
    "color_img=np.array(color_img,np.int32)\n",
    "            \n",
    "plt.imshow(color_img)\n",
    "\n",
    "a = Line2D([0], [0], color='#%02x%02x%02x' % tuple(DEFAULT_COLOR), lw=4) \n",
    "clines = [a] \n",
    "for c in list(RGB_MAP.values()):  \n",
    "    hex_color='#%02x%02x%02x' % tuple(c)\n",
    "    a = Line2D([0], [0], color=hex_color, lw=4) \n",
    "    clines.append(a)\n",
    "\n",
    "ax.legend(clines, [ \"Background\", \"Lower ring\", \"Outer\", \"Inner\", \"Peak\"],loc=(1.1,0.5))\n",
    "\n",
    "plt.savefig(PREPROCESSED_DATA + \"SYNTHETIC/visual.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [\"augite\", \"enstatite\", \"labradorite\",  \"olivine (Fo51)\"]\n",
    "# background, lower ring, outer ring, inner ring, peak\n",
    "testing_regions = [\"b\", \"l\", \"o\", \"i\", \"p\"]\n",
    "m_type_map = { 0:\"b\", 1:\"l\", 2 :\"o\", 3 :\"i\", 4:\"p\"}\n",
    "# mineral assemblage for each region\n",
    "region_ms = {\"b\": [0.3, 0.2,.1,0.4],\n",
    "                \"l\": [0.7, 0, 0.3,0],\n",
    "                \"o\": [0, 0.6,0.4,0],\n",
    "                \"i\": [0.8, 0.2, 0, 0],\n",
    "                \"p\": [0.3, 0, 0, 0.7]}\n",
    "region_Ds = {\"b\": [200, 300, 100, 200],\n",
    "                \"l\": [200, 300, 100, 200],\n",
    "                \"o\": [200, 300, 100, 200],\n",
    "                \"i\": [200, 300, 100, 200],\n",
    "                \"p\": [200, 300, 100, 200]}\n",
    "region_Rs = {}\n",
    "\n",
    "# Mix each endmember\n",
    "for ttype in testing_regions: \n",
    "    m_map = {}\n",
    "    D_map = {}\n",
    "    for index, endmember in enumerate(USGS_PURE_ENDMEMBERS):\n",
    "        m_map[endmember] = region_ms[ttype][index]\n",
    "        D_map[endmember] = region_Ds[ttype][index]\n",
    "    r = get_USGS_r_mixed_hapke_estimate(m_map, D_map)\n",
    "    region_Rs[ttype] = r\n",
    "    \n",
    "with open(R_DIR + \"../wavelengths.pickle\", 'rb') as handle:\n",
    "    wavelengths = pickle.load(handle)\n",
    "\n",
    "r_image = np.zeros((img_width,img_height,len(wavelengths)))\n",
    "m_image = np.zeros((img_width,img_height,len(USGS_PURE_ENDMEMBERS)))\n",
    "D_image = np.zeros((img_width,img_height,len(USGS_PURE_ENDMEMBERS)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add noise below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Set DESIRED NOISE AMOUNT HERE ##################\n",
    "\n",
    "NOISE_AMOUNT = 0.005\n",
    "\n",
    "# NOISE_AMOUNT = \"POISSON\"\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from skimage.util import random_noise\n",
    "# Fill test image with synthetically mixed spectra \n",
    "i = 0\n",
    "# add a bit of noise to each spectra when creating image\n",
    "for row_index, row in enumerate(test_img):\n",
    "    for col_index, col in enumerate(row):\n",
    "        ttype_index = test_img[row_index, col_index]\n",
    "        ttype = testing_regions[int(ttype_index)]\n",
    "        cur_R = region_Rs[ttype]\n",
    "        # Add Gaussian noise \n",
    "        noise = np.random.normal(loc=0, \n",
    "                                 scale=NOISE_AMOUNT, \n",
    "                                 size=len(wavelengths))\n",
    "        noisy_r = noise + cur_R\n",
    "        # add Poisson noise\n",
    "#         noisy_r = random_noise(cur_R, mode=\"poisson\")\n",
    "        \n",
    "        r_image[row_index, col_index] = noisy_r.copy()\n",
    "#         eq=str(region_Rs[ttype])== str(r_image[row_index, col_index] ) \n",
    "        \n",
    "        m_image[row_index, col_index] = region_ms[ttype]\n",
    "        D_image[row_index, col_index] = region_Ds[ttype]\n",
    "        i+=1\n",
    "        \n",
    "STR_NOISE = str(\"_noise_\" + str(NOISE_AMOUNT))\n",
    "with open(PREPROCESSED_DATA + \"SYNTHETIC/r_img\" + STR_NOISE + \".pickle\", 'wb') as f:\n",
    "    pickle.dump(r_image, f)\n",
    "with open(PREPROCESSED_DATA + \"SYNTHETIC/m_actual\" + STR_NOISE + \".pickle\", 'wb') as f: \n",
    "    pickle.dump(m_image, f)\n",
    "with open(PREPROCESSED_DATA + \"SYNTHETIC/D_actual\" + STR_NOISE + \".pickle\", 'wb') as f:\n",
    "    pickle.dump(D_image, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is some visualization of spectra. It is currently commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original vs noise added.\n",
    "# fig, ax = plt.subplots(figsize=(6, 5), dpi=400)\n",
    "# ax.plot(wavelengths, samp_spectra , color=\"blue\", label=\"Orig\")\n",
    "# ax.plot(wavelengths, pois_spectra, color=\"red\", label=\"Noisy\")\n",
    "# ax.set_ylabel(\"Reflectance\")\n",
    "# ax.set_xlabel(\"Wavelength\")\n",
    "# ax.set_ylim((0, 1))\n",
    "# ax.set_xlim((min(wavelengths), max(wavelengths)))\n",
    "# plt.legend(loc='best', fontsize=12)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# max_val = r_image.max()\n",
    "# PEAK = 0.5 \n",
    "# (r_image/(max_val * PEAK ) ) / PEAK\n",
    "\n",
    "# p_r = np.random.poisson(lam=[0.02, 0.03])\n",
    "\n",
    "# import numpy as np\n",
    "# image = read_image(\"YOUR_IMAGE\")  # need a rescale to be more realistic\n",
    "# noisy = np.random.poisson(image / 255.0 * PEAK) / PEAK * 255  # noisy image\n",
    "\n",
    "# import numpy as np\n",
    "# image = read_image(\"YOUR_IMAGE\") \n",
    "# noisemap = create_noisemap() \n",
    "# noisy = image + np.random.poisson(noisemap)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(PREPROCESSED_DATA + \"SYNTHETIC/r_img_noise_0.pickle\", 'rb') as F:\n",
    "#     R_image = pickle.load(F)\n",
    "# pix_10_10_orig = R_image[0,6]\n",
    "\n",
    "# with open(PREPROCESSED_DATA + \"SYNTHETIC/r_img_noise_0.01.pickle\", 'rb') as F:\n",
    "#     nr_image = pickle.load(F)\n",
    "# pix_10_10_noise = nr_image[0,6]\n",
    "\n",
    "\n",
    "# np.sqrt(np.mean((pix_10_10_orig-pix_10_10_noise )**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot original vs noise added.\n",
    "# fig, ax = plt.subplots(figsize=(6, 5), dpi=400)\n",
    "# ax.plot(wavelengths, pix_10_10_orig, color=\"blue\", label=\"Orig\")\n",
    "# ax.plot(wavelengths, pix_10_10_noise, color=\"red\", label=\"Noisy\")\n",
    "# ax.set_ylabel(\"Reflectance\")\n",
    "# ax.set_xlabel(\"Wavelength\")\n",
    "# ax.set_ylim((0, 1))\n",
    "# ax.set_xlim((min(wavelengths), max(wavelengths)))\n",
    "# plt.legend(loc='best', fontsize=12)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic image testing\n",
    "\n",
    "Below shows how to pull in the synthetic image (created above) and run it on the models. You do not need to recreate the synthetic image each time (the above code). You simply create it once, and then use the following code to run it however you'd like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Set testing NOISE AMOUNT HERE ##################\n",
    "\n",
    "NOISE_AMOUNT = 0.005\n",
    "\n",
    "##################################################################\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from model.models import *\n",
    "from testing.run_inference import *\n",
    "from preprocessing.generate_USGS_data import generate_image\n",
    "from utils.plotting import *\n",
    "from utils.constants import *\n",
    "\n",
    "STR_NOISE = \"_noise_\" + str(NOISE_AMOUNT)\n",
    "# STR_NOISE=\"\"\n",
    "\n",
    "with open(PREPROCESSED_DATA + \"SYNTHETIC/m_actual\" + STR_NOISE + \".pickle\", 'rb') as F:\n",
    "    m_actual = pickle.load(F)\n",
    "with open(PREPROCESSED_DATA + \"SYNTHETIC/D_actual\" + STR_NOISE + \".pickle\", 'rb') as F:\n",
    "    D_actual = pickle.load(F)\n",
    "with open(PREPROCESSED_DATA + \"SYNTHETIC/r_img\" + STR_NOISE + \".pickle\", 'rb') as F:\n",
    "    R_image = pickle.load(F)\n",
    "\n",
    "# row_min = 12\n",
    "# row_max = 18\n",
    "# col_min = 12\n",
    "# col_max = 18\n",
    "\n",
    "# m_actual = m_actual[row_min:row_max,col_min:col_max,:]\n",
    "# D_actual = D_actual[row_min:row_max,col_min:col_max,:]\n",
    "# R_image = R_image[row_min:row_max,col_min:col_max,:]\n",
    "# print(\"Num pixels \" + str(R_image.shape[0] * R_image.shape[1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Run on Independent model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time() \n",
    "\n",
    "m_est, D_est = ind_model(iterations=5,\n",
    "                         image=R_image,\n",
    "                         C=10,\n",
    "                         V=50)\n",
    "end = time.time()\n",
    "mins = (end - start)/60\n",
    "hours = mins/60\n",
    "print(\"Took \" + str(int(mins)) + \" minutes, or \" \n",
    "        + str(round(hours,2)) + \" hours.\")\n",
    "\n",
    "EXP_NAME = \"TEST_MODELS\"\n",
    "if not os.path.exists('../output/' + EXP_NAME):\n",
    "    os.makedirs('../output/' + EXP_NAME)\n",
    "record_output(m_actual, D_actual, m_est, D_est, \"ind/\", EXP_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  Run on Segmentation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_est, D_est = seg_model(seg_iterations=80000, \n",
    "                            iterations=200, \n",
    "                            image=R_image,\n",
    "                            C=10,\n",
    "                            V=50,\n",
    "                            MAX_SAD=0.029)\n",
    "record_output(m_actual, D_actual, m_est, D_est, \"seg/\", EXP_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run on MRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m_est, D_est = mrf_model(iterations=10, \n",
    "                            image=R_image,\n",
    "                            C=10,\n",
    "                            V=50)\n",
    "record_output(m_actual, D_actual, m_est, D_est, \"mrf/\",EXP_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may also use testing/run_inference.py to run these models. That is generally how we run it when doing 'real runs' in the background. Go in that file, edit the main function how you'd like, then you can run it on laplace using (remember, your virtualenv should be enabled before calling this):\n",
    "\n",
    "python run_inference.py > output.log & \n",
    "\n",
    "You can view the output.log using cat:\n",
    "\n",
    "cat output.log\n",
    "\n",
    "And, you can change the number of CPUs in utils/constants.py, in the parameter called NUM_CPUS. Default is 8. On laplace you can use more, but do not exceed ~24 (because it is a shared server and so we do not want to overload it and get in the way of others). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spec_368",
   "language": "python",
   "name": "spec_368"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
