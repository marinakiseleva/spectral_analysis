{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from model.inference import * \n",
    "from utils.access_data import *\n",
    "from utils.constants import *\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR = DATA_DIR + 'GALE_CRATER/cartOrder/cartorder/'\n",
    "image_file = IMG_DIR + 'layered_img_sec_100_150.pickle'\n",
    "wavelengths_file = IMG_DIR + 'layered_wavelengths.pickle'\n",
    "\n",
    "# Normalize spectra across RELAB, USGS, and CRISM per each CRISM image\n",
    "# (since different CRISM images have different wavelengths)\n",
    "record_reduced_spectra(wavelengths_file)\n",
    "\n",
    "image = get_CRISM_data(image_file, wavelengths_file, CRISM_match=True)\n",
    "print(\"CRISM image size \" + str(image.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "plot spectra of random pixels from image. frt0002037a_07_if165l_trr3_CAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load \"l\" image, reset all NULLs to 0 \n",
    "CRISM_DATA_PATH = DATA_DIR + 'GALE_CRATER_TEST_2/'\n",
    "CRISM_IMG = CRISM_DATA_PATH + 'frt0000c0ef_07_if165l_trr3_CAT.img'\n",
    "spy_image = envi.open(file=CRISM_IMG + '.hdr')\n",
    "\n",
    "\n",
    "image_arr = spy_image[:,:,:]\n",
    "img= np.where(image_arr[:,:,:] == 65535, 0, image_arr) \n",
    "# S_IMG_WAVELENGTHS = CRISM_DATA_PATH + 'l_pixel_x_201_y_200.csv'\n",
    "wavelengths = get_CRISM_wavelengths(CRISM_DATA_PATH + 'pixel_x_262_y_136.csv')\n",
    "\n",
    "\n",
    "\n",
    "print(len(wavelengths))\n",
    "print(img.shape)\n",
    "\n",
    "bands = (300, 200, 50)\n",
    "from spectral import imshow\n",
    "imshow(data=img, bands=bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  height = 450\n",
    "#  width = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral import imshow\n",
    "\n",
    "def plot_cutout_spectra(img, wavelengths, sec_width, sec_height, xstart, ystart, bands):\n",
    "    \"\"\"\n",
    "    Visualize subsection of image and corresponding spectra to see variance\n",
    "    :param sec_width: number of columns to include\n",
    "    :param sec_height: number of rows to include\n",
    "    :param xstart: column to start at (where 0 is left most column)\n",
    "    :param ystart: row to start at (where 0 is top row)\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(2, 1, constrained_layout=True,  dpi=300 ) # figsize=(4, 2), dpi=DPI\n",
    "    \n",
    "    height, width, num_wavelengths = img.shape\n",
    "    \n",
    "    avg_spectra = np.zeros(num_wavelengths)\n",
    "    num_pixels = sec_width*sec_height\n",
    "     \n",
    "    for i in range(sec_height):\n",
    "        for j in range(sec_width): \n",
    "                            # img [ height, width ]\n",
    "            pixel_spectra = img[i+ystart,j+xstart]\n",
    "            ax[0].plot(wavelengths, pixel_spectra, linewidth=0.5)\n",
    "            avg_spectra += pixel_spectra \n",
    "            \n",
    "             \n",
    "    avg_spectra = avg_spectra/num_pixels\n",
    "    ax[0].plot(wavelengths, avg_spectra, linewidth=1.0, color='red')\n",
    "    \n",
    "    ax[0].set_xlabel(\"Wavelength\")\n",
    "    ax[0].set_ylabel(\"Reflectance\")\n",
    "    ax[0].set_title(\"Spectra\")\n",
    "    ax[0].set_ylim((0, 1))\n",
    "\n",
    "    for i in range(sec_height):\n",
    "        for j in range(sec_width): \n",
    "            pixel_spectra = img[i+ystart,j+xstart] \n",
    "            ax[1].plot(wavelengths, pixel_spectra-avg_spectra)\n",
    "    ax[1].set_title(\"Normalied Spectra (avg subtracted)\")\n",
    "    ax[1].set_xlabel(\"Wavelength\")\n",
    "    ax[1].set_ylabel(\"reflectance - avg\")\n",
    "    ax[1].set_ylim((0,.5))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "     \n",
    "    view = imshow(data=img[xstart:(xstart+sec_height),ystart:(ystart+sec_width),:], bands=bands)\n",
    "    return avg_spectra/num_pixels\n",
    "\n",
    "    \n",
    "\n",
    "bands = (300, 200, 50)\n",
    "avg_spectra=plot_cutout_spectra(img=img,\n",
    "                    wavelengths=wavelengths,\n",
    "                    sec_width = 600,\n",
    "                    sec_height = 400,\n",
    "                    xstart = 20,\n",
    "                    ystart = 20,\n",
    "                    bands=bands)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PT sampler testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emcee import PTSampler\n",
    "\n",
    "# mu1 = [1, 1], mu2 = [-1, -1]\n",
    "mu1 = np.ones(2)\n",
    "mu2 = -np.ones(2)\n",
    "\n",
    "# Width of 0.1 in each dimension\n",
    "sigma1inv = np.diag([100.0, 100.0])\n",
    "sigma2inv = np.diag([100.0, 100.0])\n",
    "\n",
    "def logl(x):\n",
    "    dx1 = x - mu1\n",
    "    dx2 = x - mu2\n",
    "\n",
    "    return np.logaddexp(-np.dot(dx1, np.dot(sigma1inv, dx1))/2.0,\n",
    "                        -np.dot(dx2, np.dot(sigma2inv, dx2))/2.0)\n",
    "\n",
    "# Use a flat prior\n",
    "def logp(x):\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntemps = 4\n",
    "nwalkers = 10\n",
    "ndim = 2\n",
    "\n",
    "num_burnin_iterations = 100\n",
    "\n",
    "sampler=PTSampler(ntemps, nwalkers, ndim, logl, logp)\n",
    "p0 = np.random.uniform(low=-1.0, high=1.0, size=(ntemps, nwalkers, ndim))\n",
    "for p, lnprob, lnlike in sampler.sample(p0, iterations=num_burnin_iterations):\n",
    "    pass\n",
    "sampler.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At each iteration, this generator for PTSampler yields\n",
    "\n",
    "# p, the current position of the walkers.\n",
    "# lnprob the current posterior values for the walkers.\n",
    "# lnlike the current likelihood values for the walkers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 100\n",
    "\n",
    "for p, lnprob, lnlike in sampler.sample(p0=p, lnprob0=lnprob,\n",
    "                                           lnlike0=lnlike,\n",
    "                                           iterations=num_iterations, \n",
    "                                        thin=10):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sampler.chain.shape == (ntemps, nwalkers, 20, ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sampler.chain.shape == (ntemps, nwalkers, 1000, ndim)\n",
    "\n",
    "# Chain has shape (ntemps, nwalkers, nsteps, ndim)\n",
    "# Zero temperature mean:\n",
    "mu0 = np.mean(np.mean(sampler.chain[0,...], axis=0), axis=0)\n",
    "\n",
    "# Longest autocorrelation length (over any temperature)\n",
    "max_acl = np.max(sampler.acor)\n",
    "\n",
    "# etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to infer single endmember."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from model.inference import *\n",
    "from model.hapke_model import get_USGS_r_mixed_hapke_estimate\n",
    "from preprocessing.generate_USGS_data import generate_image\n",
    "from utils.plotting import *\n",
    "from utils.access_data import *\n",
    "from utils.constants import *\n",
    "\n",
    "def get_rmse(a, b): \n",
    "    return np.sqrt(np.mean((a - b)**2))\n",
    "\n",
    "def print_error(m_actual, D_actual, m_est, D_est): \n",
    "    m_rmse = str(round(get_rmse(m_actual, m_est), 2))\n",
    "    D_rmse = str(round(get_rmse(D_actual, D_est), 2))\n",
    "    print(str(np.array(D_actual)) + \", \"  + str(m_est) + \", \" + str(m_rmse) + \", \" + str(D_est) + \", \" + str(D_rmse))\n",
    "    return m_rmse, D_rmse\n",
    "\n",
    "plot_endmembers(CRISM_match=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference(m_sample, D_sample, name):\n",
    "    true_m = convert_arr_to_dict(m_sample)\n",
    "    true_D = convert_arr_to_dict(D_sample)\n",
    "    r_actual = get_USGS_r_mixed_hapke_estimate(m=true_m, D=true_D)\n",
    "    est_m, est_D = infer_datapoint(d=r_actual,\n",
    "                                   iterations=NUM_ITERATIONS, \n",
    "                                   C=10, \n",
    "                                   V=GRAIN_SIZE_COVARIANCE)\n",
    "    m_rmse, D_rmse=print_error(m_sample, D_sample, est_m, est_D)\n",
    "    wavelengths = get_USGS_wavelengths()\n",
    "    r_est = get_USGS_r_mixed_hapke_estimate(convert_arr_to_dict(est_m),  convert_arr_to_dict(est_D))\n",
    "    fig, ax = plt.subplots(1, 1, constrained_layout=True, figsize=(FIG_WIDTH, FIG_HEIGHT), dpi=DPI)\n",
    "    ax.plot(wavelengths, r_est, label = \"Estimated\", color = \"orange\")\n",
    "    ax.plot(wavelengths, r_actual, label = \"Actual\", color=\"blue\")\n",
    "    ax.set_xlabel(\"Wavelength\")\n",
    "    ax.set_ylabel(\"Reflectance\")\n",
    "    ax.legend()\n",
    "    ax.set_title(\"RMSE M: \" + str(m_rmse) + \", D: \" + str(D_rmse))\n",
    "    plt.ylim((0, 1)) \n",
    "    plt.savefig(\"../output/tests/\" + str(name) + \".pdf\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# [\"augite\", \"enstatite\", \"labradorite\",  \"olivine (Fo51)\"]\n",
    "m_sample = [0.6, 0.05,.05,0.4]\n",
    "D_sample = [200, 300, 100, 200]\n",
    "NAME = \"mixed_7\"\n",
    "GRAIN_SIZE_COVARIANCE = 50\n",
    "NUM_ITERATIONS = 15\n",
    "test_inference(m_sample, D_sample, NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Image Generation\n",
    "Create synthetic image resembling some realistic geology to have single, useful test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 2D Numpy Matrix based on circles\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib\n",
    "def points_in_circle_np(radius, x0=0, y0=0):\n",
    "    \"\"\"\n",
    "    Get X, Y coords for given circle\n",
    "    \"\"\"\n",
    "    x_ = np.arange(x0 - radius - 1, x0 + radius + 1, dtype=int)\n",
    "    y_ = np.arange(y0 - radius - 1, y0 + radius + 1, dtype=int)\n",
    "    x, y = np.where((x_[:,np.newaxis] - x0)**2 + (y_ - y0)**2 <= radius**2)\n",
    "    # x, y = np.where((np.hypot((x_-x0)[:,np.newaxis], y_-y0)<= radius)) # alternative implementation\n",
    "    for x, y in zip(x_[x], y_[y]):\n",
    "        yield x, y\n",
    "\n",
    "        \n",
    "\n",
    "img_width = 24\n",
    "img_height = 24\n",
    "color_img = np.zeros((img_width,img_height,3))\n",
    "test_img = np.zeros((img_width,img_height,1))\n",
    "\n",
    "center_X = int(img_height/2)\n",
    "center_Y = int(img_width/2)\n",
    "outer_circle = points_in_circle_np(9, x0=center_X, y0=center_Y)\n",
    "medium_circle =  points_in_circle_np(6, x0=center_X, y0=center_Y)\n",
    "inner_circle =  points_in_circle_np(3, x0=center_X+1, y0=center_Y+1)\n",
    "lower_ring = points_in_circle_np(11, x0=center_X, y0=center_Y-1)\n",
    "\n",
    "circles = [lower_ring, \n",
    "           outer_circle, \n",
    "           medium_circle,\n",
    "           inner_circle]\n",
    "LR_C = [255, 102, 255]\n",
    "O_C = [102, 255, 204]\n",
    "M_C = [51, 51, 255]\n",
    "I_C = [51, 102, 255]\n",
    "\n",
    "RGB_MAP = {0: LR_C,\n",
    "          1: O_C,\n",
    "          2: M_C,\n",
    "          3: I_C}\n",
    "DEFAULT_COLOR =  [153, 51, 51]\n",
    "\n",
    "for row_index, row in enumerate(color_img):\n",
    "    for col_index, col in enumerate(row):\n",
    "        color_img[row_index,col_index] = DEFAULT_COLOR\n",
    "        test_img[row_index,col_index] = 0\n",
    "            \n",
    "for i, circle in enumerate(circles):\n",
    "    for point in circle:\n",
    "        x=point[0]\n",
    "        y=point[1] \n",
    "        if i != 0:\n",
    "            color_img[x,y] = RGB_MAP[i]\n",
    "            test_img[x,y] = i + 1\n",
    "        else:\n",
    "            # only do lower, ring so threshold x \n",
    "            if x >= int(img_height*0.6):\n",
    "                color_img[x,y] = RGB_MAP[i]\n",
    "                test_img[x,y] = i + 1\n",
    "# Plot image\n",
    "figure, ax = plt.subplots(1)\n",
    "color_img=np.array(color_img,np.int32)\n",
    "            \n",
    "plt.imshow(color_img)\n",
    "\n",
    "a = Line2D([0], [0], color='#%02x%02x%02x' % tuple(DEFAULT_COLOR), lw=4) \n",
    "clines = [a] \n",
    "for c in list(RGB_MAP.values()):  \n",
    "    hex_color='#%02x%02x%02x' % tuple(c)\n",
    "    a = Line2D([0], [0], color=hex_color, lw=4) \n",
    "    clines.append(a)\n",
    "\n",
    "ax.legend(clines, [ \"Background\", \"Lower ring\", \"Outer\", \"Inner\", \"Peak\"],loc=(1.1,0.5))\n",
    "\n",
    "plt.savefig(PREPROCESSED_DATA + \"SYNTHETIC/visual.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [\"augite\", \"enstatite\", \"labradorite\",  \"olivine (Fo51)\"]\n",
    "testing_regions = [\"b\", \"l\", \"o\", \"i\", \"p\"]\n",
    "m_type_map = { 0:\"b\", 1:\"l\", 2 :\"o\", 3 :\"i\", 4:\"p\"}\n",
    "region_ms = {\"b\": [0.3, 0.2,.1,0.4],\n",
    "                \"l\": [0.7, 0, 0.3,0],\n",
    "                \"o\": [0, 0.6,0.4,0],\n",
    "                \"i\": [0.8, 0.2, 0, 0],\n",
    "                \"p\": [0.3, 0, 0, 0.7]}\n",
    "region_Ds = {\"b\": [200, 300, 100, 200],\n",
    "                \"l\": [200, 300, 100, 200],\n",
    "                \"o\": [200, 300, 100, 200],\n",
    "                \"i\": [200, 300, 100, 200],\n",
    "                \"p\": [200, 300, 100, 200]}\n",
    "region_Rs = {}\n",
    "\n",
    "# Mix each endmember; and then just add a bit of noise when creating image\n",
    "for ttype in testing_regions: \n",
    "    m_map = {}\n",
    "    D_map = {}\n",
    "    for index, endmember in enumerate(USGS_PURE_ENDMEMBERS):\n",
    "        m_map[endmember] = region_ms[ttype][index]\n",
    "        D_map[endmember] = region_Ds[ttype][index]\n",
    "    r = get_USGS_r_mixed_hapke_estimate(m_map, D_map)\n",
    "    region_Rs[ttype] = r\n",
    "    \n",
    "with open(R_DIR + \"../wavelengths.pickle\", 'rb') as handle:\n",
    "    wavelengths = pickle.load(handle)\n",
    "\n",
    "    \n",
    "r_image = np.zeros((img_width,img_height,len(wavelengths)))\n",
    "m_image = np.zeros((img_width,img_height,len(USGS_PURE_ENDMEMBERS)))\n",
    "D_image = np.zeros((img_width,img_height,len(USGS_PURE_ENDMEMBERS)))\n",
    "\n",
    "# Fill test image with synthetically mixed spectra\n",
    "for row_index, row in enumerate(test_img):\n",
    "    for col_index, col in enumerate(row):\n",
    "        ttype_index = test_img[row_index, col_index]\n",
    "        ttype = testing_regions[int(ttype_index)]\n",
    "        cur_R = region_Rs[ttype]\n",
    "        # Add noise here\n",
    "#         noise = np.random.normal(loc=0,\n",
    "#                                      scale=noise_scale,\n",
    "#                                      size=len(wavelengths))\n",
    "        r_image[row_index, col_index] = cur_R #  + noise\n",
    "        m_image[row_index, col_index] = region_ms[ttype]\n",
    "        D_image[row_index, col_index] = region_Ds[ttype]\n",
    "        \n",
    "\n",
    "with open(PREPROCESSED_DATA + \"SYNTHETIC/r_img.pickle\", 'wb') as f:\n",
    "    pickle.dump(r_image, f)\n",
    "with open(PREPROCESSED_DATA + \"SYNTHETIC/m_actual.pickle\", 'wb') as f: \n",
    "    pickle.dump(m_image, f)\n",
    "with open(PREPROCESSED_DATA + \"SYNTHETIC/D_actual.pickle\", 'wb') as f:\n",
    "    pickle.dump(D_image, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic image testing\n",
    "\n",
    "Determine why there are columns of pixels with same inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from model.models import *\n",
    "from testing.run_inference import *\n",
    "from preprocessing.generate_USGS_data import generate_image\n",
    "from utils.plotting import *\n",
    "from utils.constants import *\n",
    "\n",
    "with open(PREPROCESSED_DATA + \"SYNTHETIC/m_actual.pickle\", 'rb') as F:\n",
    "    m_actual = pickle.load(F)\n",
    "with open(PREPROCESSED_DATA + \"SYNTHETIC/D_actual.pickle\", 'rb') as F:\n",
    "    D_actual = pickle.load(F)\n",
    "with open(PREPROCESSED_DATA + \"SYNTHETIC/r_img.pickle\", 'rb') as F:\n",
    "    R_image = pickle.load(F)\n",
    "\n",
    "row_min = 1\n",
    "row_max = 5\n",
    "col_min = 1\n",
    "col_max = 5\n",
    "\n",
    "m_actual = m_actual[row_min:row_max,col_min:col_max,:]\n",
    "D_actual = D_actual[row_min:row_max,col_min:col_max,:]\n",
    "R_image = R_image[row_min:row_max,col_min:col_max,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "m_est, D_est = ind_model(iterations=200,\n",
    "                         image=R_image,\n",
    "                         C=10,\n",
    "                         V=50)\n",
    "\n",
    "EXP_NAME = \"TEST_SYNTHETIC2\"\n",
    "if not os.path.exists('../output/' + EXP_NAME):\n",
    "    os.makedirs('../output/' + EXP_NAME)\n",
    "record_output(m_actual, D_actual, m_est, D_est, \"ind/\", EXP_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spec_368",
   "language": "python",
   "name": "spec_368"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
