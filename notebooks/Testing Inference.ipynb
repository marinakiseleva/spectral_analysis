{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to infer single endmember."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from model.inference import *\n",
    "from model.hapke_model import get_USGS_r_mixed_hapke_estimate\n",
    "from preprocessing.generate_USGS_data import generate_image\n",
    "from utils.plotting import *\n",
    "from utils.access_data import *\n",
    "from utils.constants import *\n",
    "\n",
    "def get_rmse(a, b): \n",
    "    return np.sqrt(np.mean((a - b)**2))\n",
    "\n",
    "def print_error(m_actual, D_actual, m_est, D_est): \n",
    "    m_rmse = str(round(get_rmse(m_actual, m_est), 2))\n",
    "    D_rmse = str(round(get_rmse(D_actual, D_est), 2))\n",
    "    print(str(np.array(D_actual)) + \", \"  + str(m_est) + \", \" + str(m_rmse) + \", \" + str(D_est) + \", \" + str(D_rmse))\n",
    "    return m_rmse, D_rmse\n",
    "\n",
    "# plot_endmembers(CRISM_match=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference(m_sample, D_sample, name):\n",
    "    true_m = convert_arr_to_dict(m_sample)\n",
    "    true_D = convert_arr_to_dict(D_sample)\n",
    "    r_actual = get_USGS_r_mixed_hapke_estimate(m=true_m, D=true_D)\n",
    "    est_m, est_D = infer_datapoint(d_seeds_index=[r_actual, 2, 0],\n",
    "                                   iterations=NUM_ITERATIONS, \n",
    "                                   C=10, \n",
    "                                   V=GRAIN_SIZE_COVARIANCE)\n",
    "    m_rmse, D_rmse=print_error(m_sample, D_sample, est_m, est_D)\n",
    "    wavelengths = get_USGS_wavelengths()\n",
    "    r_est = get_USGS_r_mixed_hapke_estimate(convert_arr_to_dict(est_m),  convert_arr_to_dict(est_D))\n",
    "    fig, ax = plt.subplots(1, 1, constrained_layout=True, figsize=(FIG_WIDTH, FIG_HEIGHT), dpi=DPI)\n",
    "    ax.plot(wavelengths, r_est, label = \"Estimated\", color = \"orange\")\n",
    "    ax.plot(wavelengths, r_actual, label = \"Actual\", color=\"blue\")\n",
    "    ax.set_xlabel(\"Wavelength\")\n",
    "    ax.set_ylabel(\"Reflectance\")\n",
    "    ax.legend()\n",
    "    ax.set_title(\"RMSE M: \" + str(m_rmse) + \", D: \" + str(D_rmse))\n",
    "    plt.ylim((0, 1)) \n",
    "    plt.savefig(\"../output/tests/\" + str(name) + \".pdf\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# [\"augite\", \"enstatite\", \"labradorite\",  \"olivine (Fo51)\"]\n",
    "m_sample = [0.6, 0.05,.05,0.4]\n",
    "D_sample = [200, 300, 100, 200]\n",
    "NAME = \"mixed_7_1000_iters\"\n",
    "GRAIN_SIZE_COVARIANCE = 50\n",
    "NUM_ITERATIONS = 1000\n",
    "test_inference(m_sample, D_sample, NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Image Generation\n",
    "Create synthetic image resembling some realistic geology to have single, useful test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 2D Numpy Matrix based on circles\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib\n",
    "def points_in_circle_np(radius, x0=0, y0=0):\n",
    "    \"\"\"\n",
    "    Get X, Y coords for given circle\n",
    "    \"\"\"\n",
    "    x_ = np.arange(x0 - radius - 1, x0 + radius + 1, dtype=int)\n",
    "    y_ = np.arange(y0 - radius - 1, y0 + radius + 1, dtype=int)\n",
    "    x, y = np.where((x_[:,np.newaxis] - x0)**2 + (y_ - y0)**2 <= radius**2)\n",
    "    # x, y = np.where((np.hypot((x_-x0)[:,np.newaxis], y_-y0)<= radius)) # alternative implementation\n",
    "    for x, y in zip(x_[x], y_[y]):\n",
    "        yield x, y\n",
    "\n",
    "        \n",
    "\n",
    "img_width = 24\n",
    "img_height = 24\n",
    "color_img = np.zeros((img_width,img_height,3))\n",
    "test_img = np.zeros((img_width,img_height,1))\n",
    "\n",
    "center_X = int(img_height/2)\n",
    "center_Y = int(img_width/2)\n",
    "outer_circle = points_in_circle_np(9, x0=center_X, y0=center_Y)\n",
    "medium_circle =  points_in_circle_np(6, x0=center_X, y0=center_Y)\n",
    "inner_circle =  points_in_circle_np(3, x0=center_X+1, y0=center_Y+1)\n",
    "lower_ring = points_in_circle_np(11, x0=center_X, y0=center_Y-1)\n",
    "\n",
    "circles = [lower_ring, \n",
    "           outer_circle, \n",
    "           medium_circle,\n",
    "           inner_circle]\n",
    "LR_C = [255, 102, 255]\n",
    "O_C = [102, 255, 204]\n",
    "M_C = [51, 51, 255]\n",
    "I_C = [51, 102, 255]\n",
    "\n",
    "RGB_MAP = {0: LR_C,\n",
    "          1: O_C,\n",
    "          2: M_C,\n",
    "          3: I_C}\n",
    "DEFAULT_COLOR =  [153, 51, 51]\n",
    "\n",
    "for row_index, row in enumerate(color_img):\n",
    "    for col_index, col in enumerate(row):\n",
    "        color_img[row_index,col_index] = DEFAULT_COLOR\n",
    "        test_img[row_index,col_index] = 0\n",
    "            \n",
    "for i, circle in enumerate(circles):\n",
    "    for point in circle:\n",
    "        x=point[0]\n",
    "        y=point[1] \n",
    "        if i != 0:\n",
    "            color_img[x,y] = RGB_MAP[i]\n",
    "            test_img[x,y] = i + 1\n",
    "        else:\n",
    "            # only do lower, ring so threshold x \n",
    "            if x >= int(img_height*0.6):\n",
    "                color_img[x,y] = RGB_MAP[i]\n",
    "                test_img[x,y] = i + 1\n",
    "# Plot image\n",
    "figure, ax = plt.subplots(1)\n",
    "color_img=np.array(color_img,np.int32)\n",
    "            \n",
    "plt.imshow(color_img)\n",
    "\n",
    "a = Line2D([0], [0], color='#%02x%02x%02x' % tuple(DEFAULT_COLOR), lw=4) \n",
    "clines = [a] \n",
    "for c in list(RGB_MAP.values()):  \n",
    "    hex_color='#%02x%02x%02x' % tuple(c)\n",
    "    a = Line2D([0], [0], color=hex_color, lw=4) \n",
    "    clines.append(a)\n",
    "\n",
    "ax.legend(clines, [ \"Background\", \"Lower ring\", \"Outer\", \"Inner\", \"Peak\"],loc=(1.1,0.5))\n",
    "\n",
    "plt.savefig(PREPROCESSED_DATA + \"SYNTHETIC/visual.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [\"augite\", \"enstatite\", \"labradorite\",  \"olivine (Fo51)\"]\n",
    "testing_regions = [\"b\", \"l\", \"o\", \"i\", \"p\"]\n",
    "m_type_map = { 0:\"b\", 1:\"l\", 2 :\"o\", 3 :\"i\", 4:\"p\"}\n",
    "region_ms = {\"b\": [0.3, 0.2,.1,0.4],\n",
    "                \"l\": [0.7, 0, 0.3,0],\n",
    "                \"o\": [0, 0.6,0.4,0],\n",
    "                \"i\": [0.8, 0.2, 0, 0],\n",
    "                \"p\": [0.3, 0, 0, 0.7]}\n",
    "region_Ds = {\"b\": [200, 300, 100, 200],\n",
    "                \"l\": [200, 300, 100, 200],\n",
    "                \"o\": [200, 300, 100, 200],\n",
    "                \"i\": [200, 300, 100, 200],\n",
    "                \"p\": [200, 300, 100, 200]}\n",
    "region_Rs = {}\n",
    "\n",
    "# Mix each endmember; and then just add a bit of noise when creating image\n",
    "for ttype in testing_regions: \n",
    "    m_map = {}\n",
    "    D_map = {}\n",
    "    for index, endmember in enumerate(USGS_PURE_ENDMEMBERS):\n",
    "        m_map[endmember] = region_ms[ttype][index]\n",
    "        D_map[endmember] = region_Ds[ttype][index]\n",
    "    r = get_USGS_r_mixed_hapke_estimate(m_map, D_map)\n",
    "    region_Rs[ttype] = r\n",
    "    \n",
    "with open(R_DIR + \"../wavelengths.pickle\", 'rb') as handle:\n",
    "    wavelengths = pickle.load(handle)\n",
    "\n",
    "    \n",
    "r_image = np.zeros((img_width,img_height,len(wavelengths)))\n",
    "m_image = np.zeros((img_width,img_height,len(USGS_PURE_ENDMEMBERS)))\n",
    "D_image = np.zeros((img_width,img_height,len(USGS_PURE_ENDMEMBERS)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Set DESIRED NOISE AMOUNT HERE ##################\n",
    "\n",
    "NOISE_AMOUNT = 0#0.01\n",
    "\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill test image with synthetically mixed spectra\n",
    "# Add noise to half of pixels, random selection\n",
    "noisy_indices = np.random.randint(1,len(wavelengths),int(len(wavelengths)/2))\n",
    "i = 0\n",
    "for row_index, row in enumerate(test_img):\n",
    "    for col_index, col in enumerate(row):\n",
    "        ttype_index = test_img[row_index, col_index]\n",
    "        ttype = testing_regions[int(ttype_index)]\n",
    "        cur_R = region_Rs[ttype]\n",
    "        \n",
    "        \n",
    "        # Add noise here\n",
    "        if i in noisy_indices:\n",
    "            noise = np.random.normal(loc=0, \n",
    "                                 scale=NOISE_AMOUNT, \n",
    "                                 size=len(wavelengths))  \n",
    "        else:\n",
    "            noise=0\n",
    "        \n",
    "        r_image[row_index, col_index] = (cur_R + noise).copy()\n",
    "        eq=str(region_Rs[ttype])== str(r_image[row_index, col_index] )\n",
    "        if not eq:\n",
    "            print(\"NOT EQUAL\")\n",
    "        \n",
    "        m_image[row_index, col_index] = region_ms[ttype]\n",
    "        D_image[row_index, col_index] = region_Ds[ttype]\n",
    "        i+=1\n",
    "        \n",
    "STR_NOISE = str(\"_noise_\" + str(NOISE_AMOUNT))\n",
    "with open(PREPROCESSED_DATA + \"SYNTHETIC/r_img\" + STR_NOISE + \".pickle\", 'wb') as f:\n",
    "    pickle.dump(r_image, f)\n",
    "with open(PREPROCESSED_DATA + \"SYNTHETIC/m_actual\" + STR_NOISE + \".pickle\", 'wb') as f: \n",
    "    pickle.dump(m_image, f)\n",
    "with open(PREPROCESSED_DATA + \"SYNTHETIC/D_actual\" + STR_NOISE + \".pickle\", 'wb') as f:\n",
    "    pickle.dump(D_image, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.segmentation import get_SAD\n",
    "get_SAD(r_image[1,2], r_image[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PREPROCESSED_DATA + \"SYNTHETIC/r_img_noise_0.pickle\", 'rb') as F:\n",
    "    R_image = pickle.load(F)\n",
    "pix_10_10_orig = R_image[0,6]\n",
    "\n",
    "with open(PREPROCESSED_DATA + \"SYNTHETIC/r_img_noise_0.01.pickle\", 'rb') as F:\n",
    "    nr_image = pickle.load(F)\n",
    "pix_10_10_noise = nr_image[0,6]\n",
    "\n",
    "\n",
    "np.sqrt(np.mean((pix_10_10_orig-pix_10_10_noise )**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original vs noise added.\n",
    "fig, ax = plt.subplots(figsize=(6, 5), dpi=400)\n",
    "ax.plot(wavelengths, pix_10_10_orig, color=\"blue\", label=\"Orig\")\n",
    "ax.plot(wavelengths, pix_10_10_noise, color=\"red\", label=\"Noisy\")\n",
    "ax.set_ylabel(\"Reflectance\")\n",
    "ax.set_xlabel(\"Wavelength\")\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_xlim((min(wavelengths), max(wavelengths)))\n",
    "plt.legend(loc='best', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic image testing\n",
    "\n",
    "Run ind model on synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Set testing NOISE AMOUNT HERE ##################\n",
    "\n",
    "NOISE_AMOUNT = 0.005\n",
    "\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from model.models import *\n",
    "from testing.run_inference import *\n",
    "from preprocessing.generate_USGS_data import generate_image\n",
    "from utils.plotting import *\n",
    "from utils.constants import *\n",
    "\n",
    "\n",
    "\n",
    "STR_NOISE = \"_noise_\" + str(NOISE_AMOUNT)\n",
    "# STR_NOISE=\"\"\n",
    "\n",
    "with open(PREPROCESSED_DATA + \"SYNTHETIC/m_actual\" + STR_NOISE + \".pickle\", 'rb') as F:\n",
    "    m_actual = pickle.load(F)\n",
    "with open(PREPROCESSED_DATA + \"SYNTHETIC/D_actual\" + STR_NOISE + \".pickle\", 'rb') as F:\n",
    "    D_actual = pickle.load(F)\n",
    "with open(PREPROCESSED_DATA + \"SYNTHETIC/r_img\" + STR_NOISE + \".pickle\", 'rb') as F:\n",
    "    R_image = pickle.load(F)\n",
    "\n",
    "# row_min = 1\n",
    "# row_max = 14\n",
    "# col_min = 1\n",
    "# col_max = 14\n",
    "\n",
    "# m_actual = m_actual[row_min:row_max,col_min:col_max,:]\n",
    "# D_actual = D_actual[row_min:row_max,col_min:col_max,:]\n",
    "# R_image = R_image[row_min:row_max,col_min:col_max,:]\n",
    "print(\"Num pixels \" + str(R_image.shape[0] * R_image.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independent model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time() \n",
    "\n",
    "m_est, D_est = ind_model(iterations=5,\n",
    "                         image=R_image,\n",
    "                         C=10,\n",
    "                         V=50)\n",
    "end = time.time()\n",
    "mins = (end - start)/60\n",
    "hours = mins/60\n",
    "print(\"Took \" + str(int(mins)) + \" minutes, or \" \n",
    "        + str(round(hours,2)) + \" hours.\")\n",
    "\n",
    "EXP_NAME = \"TEST_SYNTHETIC2\"\n",
    "if not os.path.exists('../output/' + EXP_NAME):\n",
    "    os.makedirs('../output/' + EXP_NAME)\n",
    "record_output(m_actual, D_actual, m_est, D_est, \"ind/\", EXP_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_est, D_est = seg_model(seg_iterations=80000, \n",
    "                            iterations=10, \n",
    "                            image=R_image,\n",
    "                            C=10,\n",
    "                            V=50,\n",
    "                            MAX_SAD=0.029)\n",
    "record_output(m_actual, D_actual, m_est, D_est, \"seg/\", \"TESTSEG0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining MAX_SAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_regions = [\"b\", \"l\", \"o\", \"i\", \"p\"]\n",
    "m_type_map = { 0:\"b\", 1:\"l\", 2 :\"o\", 3 :\"i\", 4:\"p\"}\n",
    "region_ms = {\"b\": [0.3, 0.2,.1,0.4],\n",
    "                \"l\": [0.7, 0, 0.3,0],\n",
    "                \"o\": [0, 0.6,0.4,0],\n",
    "                \"i\": [0.8, 0.2, 0, 0],\n",
    "                \"p\": [0.3, 0, 0, 0.7]}\n",
    "region_Ds = {\"b\": [200, 300, 100, 200],\n",
    "                \"l\": [200, 300, 100, 200],\n",
    "                \"o\": [200, 300, 100, 200],\n",
    "                \"i\": [200, 300, 100, 200],\n",
    "                \"p\": [200, 300, 100, 200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  finding max sad\n",
    "# If their SAD is <MAX_SAD we merge them. \n",
    "# Comes from manually examining pure data spectra vs. derived Hapke model spectra where dominant mineral is 80%. \n",
    "#\n",
    "from model.segmentation import get_SAD\n",
    "\n",
    "m_map = {}\n",
    "D_map = {}\n",
    "ttype='b'\n",
    "for index, endmember in enumerate(USGS_PURE_ENDMEMBERS):\n",
    "    m_map[endmember] = region_ms[ttype][index]\n",
    "    D_map[endmember] = region_Ds[ttype][index]\n",
    "r = get_USGS_r_mixed_hapke_estimate(m_map, D_map)\n",
    "    \n",
    "with open(R_DIR + \"../wavelengths.pickle\", 'rb') as handle:\n",
    "    wavelengths = pickle.load(handle)\n",
    "\n",
    "NOISE_AMOUNT=0\n",
    "sads=[]\n",
    "for t in range(50):\n",
    "    noise = np.random.normal(loc=0, \n",
    "                             scale=NOISE_AMOUNT, \n",
    "                             size=len(wavelengths)) \n",
    "\n",
    "    noisy_r = r + noise\n",
    "    for i, v in enumerate(noisy_r):\n",
    "        if v <= 0:\n",
    "            noisy_r[i]=0\n",
    "\n",
    "    s=get_SAD(a=r, b=noisy_r)\n",
    "    sads.append(s)\n",
    "avg_SAD = np.mean(s)\n",
    "print(\"Average SAD between pure and noisy R for ttype \" + str(ttype) + \n",
    "      \" with noise = \" + str(NOISE_AMOUNT) + \" is = \" + str(round(avg_SAD,9)))\n",
    "# print(\"we merge when target SAD < MAX_SAD, so wouldthis pass? \" + str(avg_SAD<MAX_SAD))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5), dpi=400)\n",
    "ax.plot(wavelengths, r, color=\"blue\", label=\"Orig\")\n",
    "ax.plot(wavelengths, noisy_r, color=\"red\", label=\"Noisy\")\n",
    "ax.set_ylabel(\"Reflectance\")\n",
    "ax.set_xlabel(\"Wavelength\")\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_xlim((min(wavelengths), max(wavelengths)))\n",
    "plt.legend(loc='best', fontsize=12)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spec_368",
   "language": "python",
   "name": "spec_368"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
