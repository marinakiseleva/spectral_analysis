{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from model.inference import *\n",
    "from model.hapke_model import get_USGS_r_mixed_hapke_estimate\n",
    "from utils.access_data import *\n",
    "from utils.constants import *\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR = DATA_DIR + 'GALE_CRATER/cartOrder/cartorder/'\n",
    "image_file = IMG_DIR + 'layered_img_sec_100_150.pickle'\n",
    "wavelengths_file = IMG_DIR + 'layered_wavelengths.pickle'\n",
    "\n",
    "# Normalize spectra across RELAB, USGS, and CRISM per each CRISM image\n",
    "# (since different CRISM images have different wavelengths)\n",
    "record_reduced_spectra(wavelengths_file)\n",
    "\n",
    "image = get_CRISM_data(image_file, wavelengths_file, CRISM_match=True)\n",
    "print(\"CRISM image size \" + str(image.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "plot spectra of random pixels from image. frt0002037a_07_if165l_trr3_CAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load \"l\" image, reset all NULLs to 0 \n",
    "CRISM_DATA_PATH = DATA_DIR + 'GALE_CRATER_TEST_2/'\n",
    "CRISM_IMG = CRISM_DATA_PATH + 'frt0000c0ef_07_if165l_trr3_CAT.img'\n",
    "spy_image = envi.open(file=CRISM_IMG + '.hdr')\n",
    "\n",
    "\n",
    "image_arr = spy_image[:,:,:]\n",
    "img= np.where(image_arr[:,:,:] == 65535, 0, image_arr) \n",
    "# S_IMG_WAVELENGTHS = CRISM_DATA_PATH + 'l_pixel_x_201_y_200.csv'\n",
    "wavelengths = get_CRISM_wavelengths(CRISM_DATA_PATH + 'pixel_x_262_y_136.csv')\n",
    "\n",
    "\n",
    "\n",
    "print(len(wavelengths))\n",
    "print(img.shape)\n",
    "\n",
    "bands = (300, 200, 50)\n",
    "from spectral import imshow\n",
    "imshow(data=img, bands=bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  height = 450\n",
    "#  width = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral import imshow\n",
    "\n",
    "def plot_cutout_spectra(img, wavelengths, sec_width, sec_height, xstart, ystart, bands):\n",
    "    \"\"\"\n",
    "    Visualize subsection of image and corresponding spectra to see variance\n",
    "    :param sec_width: number of columns to include\n",
    "    :param sec_height: number of rows to include\n",
    "    :param xstart: column to start at (where 0 is left most column)\n",
    "    :param ystart: row to start at (where 0 is top row)\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(2, 1, constrained_layout=True,  dpi=300 ) # figsize=(4, 2), dpi=DPI\n",
    "    \n",
    "    height, width, num_wavelengths = img.shape\n",
    "    \n",
    "    avg_spectra = np.zeros(num_wavelengths)\n",
    "    num_pixels = sec_width*sec_height\n",
    "     \n",
    "    for i in range(sec_height):\n",
    "        for j in range(sec_width): \n",
    "                            # img [ height, width ]\n",
    "            pixel_spectra = img[i+ystart,j+xstart]\n",
    "            ax[0].plot(wavelengths, pixel_spectra, linewidth=0.5)\n",
    "            avg_spectra += pixel_spectra \n",
    "            \n",
    "             \n",
    "    avg_spectra = avg_spectra/num_pixels\n",
    "    ax[0].plot(wavelengths, avg_spectra, linewidth=1.0, color='red')\n",
    "    \n",
    "    ax[0].set_xlabel(\"Wavelength\")\n",
    "    ax[0].set_ylabel(\"Reflectance\")\n",
    "    ax[0].set_title(\"Spectra\")\n",
    "    ax[0].set_ylim((0, 1))\n",
    "\n",
    "    for i in range(sec_height):\n",
    "        for j in range(sec_width): \n",
    "            pixel_spectra = img[i+ystart,j+xstart] \n",
    "            ax[1].plot(wavelengths, pixel_spectra-avg_spectra)\n",
    "    ax[1].set_title(\"Normalied Spectra (avg subtracted)\")\n",
    "    ax[1].set_xlabel(\"Wavelength\")\n",
    "    ax[1].set_ylabel(\"reflectance - avg\")\n",
    "    ax[1].set_ylim((0,.5))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "     \n",
    "    view = imshow(data=img[xstart:(xstart+sec_height),ystart:(ystart+sec_width),:], bands=bands)\n",
    "    return avg_spectra/num_pixels\n",
    "\n",
    "    \n",
    "\n",
    "bands = (300, 200, 50)\n",
    "avg_spectra=plot_cutout_spectra(img=img,\n",
    "                    wavelengths=wavelengths,\n",
    "                    sec_width = 600,\n",
    "                    sec_height = 400,\n",
    "                    xstart = 20,\n",
    "                    ystart = 20,\n",
    "                    bands=bands)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PT sampler testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emcee import PTSampler\n",
    "\n",
    "# mu1 = [1, 1], mu2 = [-1, -1]\n",
    "mu1 = np.ones(2)\n",
    "mu2 = -np.ones(2)\n",
    "\n",
    "# Width of 0.1 in each dimension\n",
    "sigma1inv = np.diag([100.0, 100.0])\n",
    "sigma2inv = np.diag([100.0, 100.0])\n",
    "\n",
    "def logl(x):\n",
    "    dx1 = x - mu1\n",
    "    dx2 = x - mu2\n",
    "\n",
    "    return np.logaddexp(-np.dot(dx1, np.dot(sigma1inv, dx1))/2.0,\n",
    "                        -np.dot(dx2, np.dot(sigma2inv, dx2))/2.0)\n",
    "\n",
    "# Use a flat prior\n",
    "def logp(x):\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntemps = 4\n",
    "nwalkers = 10\n",
    "ndim = 2\n",
    "\n",
    "num_burnin_iterations = 100\n",
    "\n",
    "sampler=PTSampler(ntemps, nwalkers, ndim, logl, logp)\n",
    "p0 = np.random.uniform(low=-1.0, high=1.0, size=(ntemps, nwalkers, ndim))\n",
    "for p, lnprob, lnlike in sampler.sample(p0, iterations=num_burnin_iterations):\n",
    "    pass\n",
    "sampler.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At each iteration, this generator for PTSampler yields\n",
    "\n",
    "# p, the current position of the walkers.\n",
    "# lnprob the current posterior values for the walkers.\n",
    "# lnlike the current likelihood values for the walkers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 100\n",
    "\n",
    "for p, lnprob, lnlike in sampler.sample(p0=p, lnprob0=lnprob,\n",
    "                                           lnlike0=lnlike,\n",
    "                                           iterations=num_iterations, \n",
    "                                        thin=10):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sampler.chain.shape == (ntemps, nwalkers, 20, ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sampler.chain.shape == (ntemps, nwalkers, 1000, ndim)\n",
    "\n",
    "# Chain has shape (ntemps, nwalkers, nsteps, ndim)\n",
    "# Zero temperature mean:\n",
    "mu0 = np.mean(np.mean(sampler.chain[0,...], axis=0), axis=0)\n",
    "\n",
    "# Longest autocorrelation length (over any temperature)\n",
    "max_acl = np.max(sampler.acor)\n",
    "\n",
    "# etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(3/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from model.inference import *\n",
    "from model.hapke_model import get_USGS_r_mixed_hapke_estimate\n",
    "from preprocessing.generate_USGS_data import generate_image\n",
    "\n",
    "from utils.access_data import *\n",
    "from utils.constants import *\n",
    "\n",
    "np.set_printoptions(precision=6)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = generate_image(num_mixtures=4,\n",
    "                           grid_res=2,\n",
    "                           noise_scale=0.0001,\n",
    "                           res=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.r_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ['olivine (Fo51)',\n",
    "# 'olivine (Fo80)',\n",
    "# 'augite',\n",
    "# 'labradorite',\n",
    "# 'pigeonite',\n",
    "# 'magnetite',\n",
    "# 'basaltic glass']\n",
    "# m_random = np.array([0, 0.4, 0.5,0.1, 0, 0, 0])\n",
    "# D_random = np.array([80, 80, 60, 60, 60, 60, 60])\n",
    "def get_rmse(a, b):\n",
    "    # Print error\n",
    "    return math.sqrt(np.mean((a - b)**2))\n",
    "\n",
    "\n",
    "def print_error(m_actual, D_actual, m_est, D_est):\n",
    "    print(\"Estimated m \" + str(m_est))\n",
    "    print(\"Real m    \" + str(m_actual))\n",
    "    print(\"Estimated D \" + str(D_est))\n",
    "    print(\"Real D    \" + str(D_actual))\n",
    "    m_rmse = str(round(get_rmse(m_actual, m_est), 2))\n",
    "    print(\"RMSE for m: \" + m_rmse)\n",
    "    D_rmse = str(round(get_rmse(D_actual, D_est), 2))\n",
    "    print(\"RMSE for D: \" + D_rmse)\n",
    "    return m_rmse, D_rmse\n",
    "\n",
    "m_errs = []\n",
    "D_errs = []\n",
    "r_errs = []\n",
    "# for i in range(1):\n",
    "i = 1 \n",
    "\n",
    "\n",
    "    m_random = np.random.dirichlet(np.ones(USGS_NUM_ENDMEMBERS),\n",
    "                                       size=1)[0]\n",
    "    D_random = np.random.randint(low=GRAIN_SIZE_MIN,\n",
    "                                     high=GRAIN_SIZE_MAX,\n",
    "                                     size=USGS_NUM_ENDMEMBERS)\n",
    "\n",
    "    true_m = convert_arr_to_dict(m_random)\n",
    "    true_D = convert_arr_to_dict(D_random)\n",
    "    r_actual = get_USGS_r_mixed_hapke_estimate(m=true_m, D=true_D)\n",
    "\n",
    "    np.set_printoptions(precision=2)\n",
    "    est_m, est_D = infer_datapoint(iterations=1500, d=r_actual)\n",
    " \n",
    "\n",
    "    wavelengths = N_WAVELENGTHS\n",
    "    r_est = get_USGS_r_mixed_hapke_estimate(convert_arr_to_dict(est_m),\n",
    "                                              convert_arr_to_dict(est_D))\n",
    "    \n",
    "    m_rmse, D_rmse=print_error(m_random, D_random, est_m, est_D)\n",
    "    m_errs.append(m_rmse)\n",
    "    D_errs.append(D_rmse)\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, constrained_layout=True,\n",
    "                           figsize=(FIG_WIDTH, FIG_HEIGHT), dpi=DPI)\n",
    "    ax.plot(wavelengths, r_est, label = \"Estimated\", color = \"orange\")\n",
    "    ax.plot(wavelengths, r_actual, label = \"Actual\", color=\"blue\")\n",
    "\n",
    "    ax.set_xlabel(\"Wavelength\")\n",
    "    ax.set_ylabel(\"Reflectance\")\n",
    "    ax.legend()\n",
    "    ax.set_title(\"RMSE M: \" + str(m_rmse) + \", D: \" + str(D_rmse))\n",
    "    plt.ylim((0, 1)) \n",
    "    plt.savefig(\"../output/figures/testing/sample_\" + str(i))\n",
    "    plt.show()\n",
    "    \n",
    "     \n",
    "    r_rmse = get_rmse(r_actual, r_est)\n",
    "    print(\"Reflectance RMSE: \" + str(r_rmse))\n",
    "    r_errs.append(r_rmse)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_errs_arr = np.array(m_errs)\n",
    "m_errs_arr = m_errs_arr.astype(np.float)\n",
    "\n",
    "print(\"Mean: \" + str(np.mean(m_errs_arr)) )\n",
    "print(\"Min: \" + str(np.amin(m_errs_arr)) )\n",
    "print(\"Max: \" + str(np.amax(m_errs_arr)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(N_WAVELENGTHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spec_env",
   "language": "python",
   "name": "spec_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
